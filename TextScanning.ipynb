{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from skimage.io import imread\n",
    "from skimage.color import rgb2gray\n",
    "from skimage.filters import threshold_otsu\n",
    "from skimage.filters import gaussian\n",
    "\n",
    "import matplotlib.patches as mpatches\n",
    "from skimage.measure import label, regionprops\n",
    "from skimage.util import invert\n",
    "from scipy.spatial.distance import euclidean\n",
    "\n",
    "import numpy as np\n",
    "from skimage.draw import polygon_perimeter\n",
    "from commonfunctions import *\n",
    "\n",
    "import cv2\n",
    "import numpy as np\n",
    "from commonfunctions import *\n",
    "\n",
    "from skimage.measure import compare_ssim\n",
    "import imutils\n",
    "from imutils import contours\n",
    "from skimage.segmentation import clear_border\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "alphabetics_dict = {}\n",
    "Alpha_numeric_list=['A','B','C','D','E','F','G','H','I','G','K','L','M','N','O','P','Q','R','S','T','U','V','W','X','Y','Z',\n",
    "                    '0','1','2','3','4','5','6','7','8','9',\n",
    "                    'a','b','c','d','e','f','g','h','i','g','k','l','m','n','o','p','q','r','s','t','u','v','w','x','y','z']\n",
    "\n",
    "# import image\n",
    "def read_image(image):\n",
    "    image = cv2.imread(image)\n",
    "    return image\n",
    "\n",
    "#read letters images and save their histograms\n",
    "def readletters():\n",
    "    for i in range(len(Alpha_numeric_list)):\n",
    "        alphabetics_dict.update( { Alpha_numeric_list[i] : histogram(\n",
    "            rgbtogray(read_image( \"alphanumeric/\" + Alpha_numeric_list[i] + \".png\"))) } )\n",
    "\n",
    "    return\n",
    "\n",
    "def rgbtogray(image):\n",
    "    gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "    return gray\n",
    "# cv2.imshow('threshold', thresh)\n",
    "\n",
    "# dilation\n",
    "def dilation(thresh):\n",
    "    kernel = np.ones((10, 1), np.uint8)\n",
    "    img_dilation = cv2.dilate(thresh, kernel, iterations=1)\n",
    "    return img_dilation\n",
    "# cv2.imshow('dilated', img_dilation)\n",
    "    \n",
    "# cv2.imshow('gray', gray)\n",
    "\n",
    "# binary\n",
    "def convert_to_binary(gray):\n",
    "    ret, thresh = cv2.threshold(gray, 127, 255, cv2.THRESH_BINARY_INV)\n",
    "    return ret,thresh\n",
    "\n",
    "# find contours and sort them\n",
    "def find_contours(img_dilation):\n",
    "    ctrs, hier = cv2.findContours(img_dilation.copy(), cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "    sorted_ctrs = sorted(ctrs, key=lambda ctr: cv2.boundingRect(ctr)[0])\n",
    "    return sorted_ctrs\n",
    "\n",
    "def extract_digits_and_symbols(image, charCnts, minW=5, minH=15):\n",
    "    # grab the internal Python iterator for the list of character\n",
    "    # contours, then  initialize the character ROI and location\n",
    "    # lists, respectively\n",
    "    charIter = charCnts.__iter__()\n",
    "    rois = []\n",
    "    locs = []\n",
    "\n",
    "    # keep looping over the character contours until we reach the end\n",
    "    # of the list\n",
    "    while True:\n",
    "        try:\n",
    "            # grab the next character contour from the list, compute\n",
    "            # its bounding box, and initialize the ROI\n",
    "            c = next(charIter)\n",
    "            (cX, cY, cW, cH) = cv2.boundingRect(c)\n",
    "            roi = None\n",
    "\n",
    "            # check to see if the width and height are sufficiently\n",
    "            # large, indicating that we have found a digit\n",
    "            if cW >= minW and cH >= minH:\n",
    "                # extract the ROI\n",
    "                roi = image[cY:cY + cH, cX:cX + cW]\n",
    "                rois.append(roi)\n",
    "                locs.append((cX, cY, cX + cW, cY + cH))\n",
    "\n",
    "            # otherwise, we are examining one of the special symbols\n",
    "            else:\n",
    "                # MICR symbols include three separate parts, so we\n",
    "                # need to grab the next two parts from our iterator,\n",
    "                # followed by initializing the bounding box\n",
    "                # coordinates for the symbol\n",
    "                parts = [c, next(charIter), next(charIter)]\n",
    "                (sXA, sYA, sXB, sYB) = (np.inf, np.inf, -np.inf,-np.inf)\n",
    "\n",
    "                # loop over the parts\n",
    "                for p in parts:\n",
    "                    # compute the bounding box for the part, then\n",
    "                    # update our bookkeeping variables\n",
    "                    (pX, pY, pW, pH) = cv2.boundingRect(p)\n",
    "                    sXA = min(sXA, pX)\n",
    "                    sYA = min(sYA, pY)\n",
    "                    sXB = max(sXB, pX + pW)\n",
    "                    sYB = max(sYB, pY + pH)\n",
    "\n",
    "                # extract the ROI\n",
    "                roi = image[sYA:sYB, sXA:sXB]\n",
    "                rois.append(roi)\n",
    "                locs.append((sXA, sYA, sXB, sYB))\n",
    "\n",
    "        # we have reached the end of the iterator; gracefully break\n",
    "        # from the loop\n",
    "        except StopIteration:\n",
    "            break\n",
    "\n",
    "    # return a tuple of the ROIs and locations\n",
    "    return (rois, locs)\n",
    "\n",
    "\n",
    "def ConstructOurDictionary():\n",
    "    ref = read_image('alphabets.jpg')\n",
    "    ref = cv2.cvtColor(ref, cv2.COLOR_BGR2GRAY)\n",
    "    ref = imutils.resize(ref, width=2000)\n",
    "    ref = cv2.threshold(ref, 0, 255, cv2.THRESH_BINARY_INV | cv2.THRESH_OTSU)[1]\n",
    "\n",
    "    # find contours in the MICR image (i.e,. the outlines of the\n",
    "    # characters) and sort them from left to right\n",
    "    refCnts = cv2.findContours(ref.copy(), cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "    refCnts = imutils.grab_contours(refCnts)\n",
    "    #refCnts = contours.sort_contours(refCnts, method=\"left-to-right\")[0]\n",
    "\n",
    "    # extract the digits and symbols from the list of contours, then\n",
    "    # initialize a dictionary to map the character name to the ROI\n",
    "    refROIs = extract_digits_and_symbols(ref, refCnts,minW=10, minH=20)[0]\n",
    "\n",
    "    for (name,roi) in zip(Alpha_numeric_list, refROIs):\n",
    "        #print(\"her\")\n",
    "        roi=cv2.resize(roi,(36, 36))\n",
    "        alphabetics_dict[name] = roi\n",
    "    \n",
    "#     for key in alphabetics_dict:\n",
    "#         print(key)\n",
    "#         show_images([alphabetics_dict[key]])\n",
    "    return\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Check OCR: o l  l l U \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "-1"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "ConstructOurDictionary()\n",
    "#print(alphabetics_dict)\n",
    "\n",
    "image=read_image('tnr.jpg')\n",
    "#image=read_image('abcd.jpg')\n",
    "#image=read_image('alphabets - Copy.jpg')\n",
    "\n",
    "gray=rgbtogray(image)\n",
    "ret,thresh=convert_to_binary(gray)\n",
    "# remove any pixels that are touching the borders of the image (this\n",
    "# simply helps us in the next step when we prune contours)\n",
    "thresh = clear_border(thresh)\n",
    "img_dilation=dilation(thresh)\n",
    "sorted_cntrs=find_contours(img_dilation)\n",
    "\n",
    "groupLocations=[] #will contain the digit locations\n",
    "for i, ctr in enumerate(sorted_cntrs):\n",
    "        x, y, w, h = cv2.boundingRect(ctr)\n",
    "        # only accept the contour region as a grouping of characters if\n",
    "        # the ROI is sufficiently large\n",
    "#         print(\"w \"+str(w))\n",
    "#         print(\"h \"+str(h))\n",
    "#         if w > 50 and h > 15:\n",
    "        groupLocations.append((x, y, w, h))\n",
    "        \n",
    "groupLocations = sorted(groupLocations, key=lambda x:x[0])       \n",
    "#print(groupLocations)\n",
    "\n",
    "output = []\n",
    "# loop over the group locations\n",
    "for (gX, gY, gW, gH) in groupLocations:\n",
    "    # initialize the group output of characters\n",
    "    groupOutput = []\n",
    "\n",
    "    # extract the group ROI of characters from the grayscale\n",
    "    # image, then apply thresholding to segment the digits from\n",
    "    # the background of the credit card\n",
    "    group = gray[gY - 5:gY + gH + 5, gX - 5:gX + gW + 5]\n",
    "    group = cv2.threshold(group, 0, 255, cv2.THRESH_BINARY_INV | cv2.THRESH_OTSU)[1]\n",
    "\n",
    "    cv2.imshow(\"Group\", group)\n",
    "    cv2.waitKey(0)\n",
    "\n",
    "    # find character contours in the group, then sort them from\n",
    "    # left to right\n",
    "    charCnts = cv2.findContours(group.copy(), cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "    charCnts = imutils.grab_contours(charCnts)\n",
    "    charCnts = contours.sort_contours(charCnts, method=\"left-to-right\")[0]\n",
    "\n",
    "    # find the characters and symbols in the group\n",
    "    (rois, locs) = extract_digits_and_symbols(group, charCnts)\n",
    "    delta=0\n",
    "    # loop over the ROIs from the group\n",
    "    for roi in rois:\n",
    "        # initialize the list of template matching scores and\n",
    "        # resize the ROI to a fixed size\n",
    "        scores = []\n",
    "        roi = cv2.resize(roi, (36, 36))\n",
    "\n",
    "        # loop over the reference character name and corresponding\n",
    "        # ROI\n",
    "        for charName in Alpha_numeric_list:\n",
    "            # apply correlation-based template matching, take the\n",
    "            # score, and update the scores list\n",
    "            result = cv2.matchTemplate(roi, alphabetics_dict[charName], cv2.TM_CCOEFF)\n",
    "            \n",
    "            (_, score, _, _) = cv2.minMaxLoc(result)\n",
    "            scores.append(score)\n",
    "\n",
    "        # the classification for the character ROI will be the\n",
    "        # reference character name with the *largest* template\n",
    "        # matching score\n",
    "        groupOutput.append(Alpha_numeric_list[np.argmax(scores)])\n",
    "\n",
    "    # draw (padded) bounding box surrounding the group along with\n",
    "    # the OCR output of the group\n",
    "    cv2.rectangle(image, (gX - 10, gY + delta - 10),\n",
    "        (gX + gW + 10, gY + gY + delta), (0, 0, 255), 2)\n",
    "    cv2.putText(image, \"\".join(groupOutput),\n",
    "        (gX - 10, gY + delta - 25), cv2.FONT_HERSHEY_SIMPLEX,\n",
    "        0.95, (0, 0, 255), 3)\n",
    "\n",
    "    # add the group output to the overall check OCR output\n",
    "    output.append(\"\".join(groupOutput))\n",
    "\n",
    "# display the output check OCR information to the screen\n",
    "print(\"Check OCR: {}\".format(\" \".join(output)))\n",
    "cv2.imshow(\"Check OCR\", image)\n",
    "cv2.waitKey(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
